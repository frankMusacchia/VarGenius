#This is the configuration file for the users of VarGenius
#This is a text file with the names of the parameters used into the the program 
#which allow to execute different purposes.
#The format is: parameter = value . 
#Comments starts with '#' symbol
#If you want to add comments, you can do it but please do not use the symbol '=' or the expression will be 
#evaluated.
#If you will add a new parameter or remove one of them
#the functionalities of VarGenius are comprompised. Please contact the author of VarGenius
#if you want to add specific functions.
#The first part of this file contains a description. VarGenius will start to read the parameters after 
#reading a long set of '#' symbols. Please do not use a long set of '#' symbols in your comments.
#
#The organization of the configuration file is the following:
#Group 1 PIPELINE STEPS EXECUTION: represents the steps that will be executed for each task
#										of the pipeline
#Group 2 NEEDED TO RUN VARGENIUS: represent the variables you need to set 
#       appropriately correspoding with your system configuration
#Group 3 JOBS RESOUucsc.hg19.faRCES REQUESTS: represent the parameters to use with QSUB command
#				for each different task of the pipeline. You need to set them accordingly with 
#       the HPC you are using.
#Group 4 SOFTWARE PARAMETERS: the parameters that you are allowed to change for the programs
#				in use in VarGenius. 
###################

*************Group 1*******************
##PIPELINE STEPS EXECUTION

#QUALITY CHECK AND TRIMMING
qc_exec = YES
trimming = YES
qc_after_trim = YES

#ALIGNMENT
#Only needed if base scores are not in Phred format
convert_scores = NO
#Merges read1 and 2 in a single file
merge_pairs = YES
align_prog_exec = YES
mark_rem_dup_exec = YES
sam_sort_idx = YES

#REFINEMENT (BestPractices GATK)
realign_target_creator = NO
indel_realigner = NO
base_recalibrator = YES
print_reads = YES

#MERGE READFILES (This task is performed automatically)
#Merge separated read files, if present
mergesam = YES
#(OPTIONAL) Runs MarkDuplicates on the merged read files
mrdup_groups = NO
#The following works only in couple with one of the prev two
index_after_merge = YES

#VARIANT CALLING
varcall = YES
catvar = YES

##GENOTYPING
#The task is performed automatically
genot = YES

##VARIANT FILTERING
varfilt = YES
varrecal = NO
apprecal = NO
genotref = NO

#PHASING
#The task is performed automatically
phasing = YES

#STATISTICS
#tigem_coverage_steps
mergebam = YES
noncovered_regions = YES
#tigem_flagstats_steps
flagstat_sorted = YES
flagstat_rmdup = YES
flagstat_inters_targ = YES
#tigem_group_coverage (Using GATK DepthOfCoverage)
coverage_analysis = YES

#OUTPUT MANAGEMENT
#Writing the output without the DB
create_vcf_to_ann = YES
annov_db_dl = YES
annot_all = YES
write_output = YES
#rearrange_output can be used with the profiles together with the variable
#output_new_cols = 1,..,N which shows the new columns order
rearrange_output = YES
get_coverage_plots = YES
update_overall_samples_plots = YES
gene_annotation = YES
generate_html = YES
#Joint analysis separation (Use YES if you want an output for each sample)
separate_analysis_from_joint = NO
send_email = NO

#IMPORT VARIANTS AND ANNOTATIONS
#Import new variants and genotypes and update frequencies
vcfimport = YES
update_frequencies = YES
#Import missing annotations
import_missing = NO

#Block database for exclusive use during the final output production
#The VCF import is by default always exclusive (param: always_block_db_vcfi)
block_db = NO




*************Group 2*******************
###NEEDED TO RUN VARGENIUS
##PROGRAM PATHS
fastqc_path = /cineca/prod/applications/fastqc/0.11.3/none/bin/fastqc
java_path = /cineca/prod/compilers/jre/1.8.0_73/none/bin/java
trimgalore_path = /cineca/prod/applications/trimgalore/0.4.1/gnu--4.8.3/trimgalore
picard_path = /cineca/prod/applications/picard/2.3.0/binary/bin/picard.jar
samtools_path = /cineca/prod/applications/samtools/1.3/gnu--4.8.3/bin/samtools
gatk_path =  /cineca/prod/applications/gatk/3.8/jre--1.8.0_73/GenomeAnalysisTK.jar
cutadapt_path = /cineca/prod/applications/cutadapt/1.9.1/python--2.7.9/bin/cutadapt
bwa_path = /cineca/prod/applications/bwa/0.7.15/intel--cs-xe-2015--binary/bin/bwa
star_path = /cineca/prod/applications/star/2.5.2a/none/bin/STAR
bedtools_path = /cineca/prod/applications/bedtools/2.24/gnu--4.8.3/bin/
annovar_path = /cineca/prod/applications/annovar/2017Jul16/none/bin/
R_path = /cineca/prod/applications/r/3.3.1/intel--pe-xe-2016--binary/bin/R

##REFERENCE FOLDERS
#Reference Genome
ref_genome_f = /pico/work/TELET_UDP/home/shared/references/genome/
#Reference fasta (You can use only hg19)
hum_gen_align = ucsc.hg19.fa

#Target Bed Files
target_reg_f = /pico/work/TELET_UDP/home/shared/references/exome

#GATK reference databases ftp://ftp.broadinstitute.org/bundle/hg19/
#Set the folder and then write just their names
gatk_ref_f = /pico/work/TELET_UDP/home/shared/db/snp/
#known indel and snps in the folder
known_mills = Mills_and_1000G_gold_standard.indels.hg19.vcf.gz
known_db_snp = dbsnp_147_hg19.vcf.gz
known_hapmap = hapmap_3.3.hg19.vcf
known_1000g = 1000G_phase1.indels.hg19.vcf.gz
known_omni = 1000G_omni2.5.hg19.vcf.gz
#Needed sites for Variant Quality Score Recalibration
known_sites_mills = Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz
known_sites_db_snp = dbsnp_147_hg19.vcf.gz
known_sites_hapmap = hapmap_3.3.hg19.sites.vcf.gz
known_sites_1000g = 1000G_phase1.snps.high_confidence.hg19.sites.vcf.gz
known_sites_omni = 1000G_phase1.indels.hg19.sites.vcf.gz
known_sites_1000gP3 = 1000G_phase3_v4_20130502.sites.vcf.gz

#Disease gene lists for coverage statistics (they are in the DATA folder into working folder)
disease_genes_lists_f = Epilessia,Lysoplex,TruSight_one,Skeletal_Dysplasia

#Scratch area
scratch_f = /pico/scratch/userexternal/fmusacch

#Storage area
storage_f = /gss/gss_work/DRES_TIGEM/home/vargenius_analyses/

#Annovar folder of databases
#NB: please use a folder name containing the version of Annovar (e.g. humandb_072017)
annovar_db_f = /pico/work/TELET_UDP/home/shared/references/annovar_072017/humandb_072017

#DATABASE configuration
db_name = telethon
db_dsn = dbi:Pg:host=postgresql.pico.cineca.it;port=5432;sslmode=allow;
db_host = postgresql.pico.cineca.it
db_user = ttudp001
db_pass = !nj5DRMi

#WEB SERVER
#This is a link to the Web Server which displays the results
#If you are not using a web server please use your work folder (e.g. /home/user/frank/vargenius_analyses)
html_host = http://UDProject:udpNGSd4t4@130.186.13.104/tigem

#Data for email sending
email_author = VarGenius@tigem.it
email_recipients = francescomusacchia@gmail.com
email_subject = VarGenius analysis is completed
email_message =  analysis is complete! Please check results in exome.tigem.it. This message is automatically generated. Please do not use the reply button. For any question send an email to francescomusacchia@gmail.com.



*************Group 3*******************
###JOBS RESOURCES REQUESTS
#Use the same parameters for qsub for all the programs (taken from program_config.txt)
#otherwise they are taken here
qsub_param_for_all = NO
#Qsub parameters that cannot be changed depending by the task:
qsub_cmd = qsub
qsub_account = TELET_TIGEM
qsub_queue = parallel
qsub_walltime = 5:00:00
qsub_restartable = YES
qsub_username = fmusacch
#Qsub parameters that will be changed depending by the task if qsub_param_for_all is YES
qsub_mem = 120GB
qsub_ncpus = 12
qsub_nodes =
qsub_select = 1
qsub_threads =
qsub_depend = afterok

#Qsub parameters changable depending by the task name
#NB: WHEN CHANGING THE TASK NAME YOU MUST CHANGE ALSO HERE
#For memory use always the measure unit (GB)
#Quality Check (this task is ran per read file)
qc_nodes =
qc_select = 1
qc_ncpus = 5
qc_threads = 5
qc_mem = 30GB
qc_walltime = 10:00:00
qc_depend = afterok
#Trimming (this task is ran per read file)
trim_mode = gatk_BP
trim_type = PE
trim_nodes =
trim_select = 1
trim_ncpus = 10
trim_threads = 10
trim_threads_mem = 5G
trim_mem = 20GB
trim_walltime = 10:00:00
trim_depend = afterany
#Alignment (this task is ran per read file)
#mode: you can choose 'bwa' or 'bwa-kit'
align_mode = gatk_BP
align_type = PE
align_nodes =
align_select = 1
align_ncpus = 10
align_threads = 10
align_threads_mem = 5G
align_mem = 20GB
align_walltime = 10:00:00
align_depend = afterok
#Refinement (this task is ran per read file)
refine_mode =
refine_nodes =
refine_select = 1
refine_ncpus = 12
refine_threads =
refine_mem = 120GB
refine_walltime = 7:00:00
refine_depend = afterok
#Merge Samples (this task is ran per-sample)
#80GB RAM is ok with Trios of Exomes in Picousr
MS_nodes =
MS_select = 1
MS_ncpus = 10
MS_threads =
MS_mem = 80GB
MS_walltime = 5:00:00
MS_depend = afterok
#Variant calling (this task is ran per-sample)
varcall_nodes =
varcall_select = 1
varcall_ncpus = 10
varcall_threads =
varcall_mem = 80GB
varcall_walltime = 10:00:00
varcall_depend = afterok
#Genotyping (this task is ran per-group)
genot_nodes =
genot_select = 1
genot_ncpus = 5
genot_threads =
genot_mem = 80GB
genot_walltime = 1:00:00
genot_depend = afterok
#variant filtering (this task is ran per-group)
varfilt_nodes =
varfilt_ncpus = 5
varfilt_select = 1
varfilt_threads =
varfilt_mem = 50GB
varfilt_walltime = 1:00:00
varilt_depend = afterok
#phasing (this task is ran per-group)
phasing_nodes =
phasing_select = 1
phasing_ncpus = 1
phasing_threads =
phasing_mem = 50GB
phasing_walltime = 1:00:00
phasing_depend = afterok
#output generation (this task is ran per-analysis)
finalout_nodes =
finalout_select = 1
finalout_ncpus = 2
finalout_threads =
finalout_mem = 20GB
finalout_walltime = 8:00:00
finalout_depend = afterok
#Fast final out
fastfout_nodes =
fastfout_select = 1
fastfout_ncpus = 2
fastfout_threads =
fastfout_mem = 50GB
fastfout_walltime = 9:30:00
fastfout_depend = afterok
#jobclean
jobclean_nodes =
jobclean_select = 1
jobclean_ncpus = 1
jobclean_threads = 1
jobclean_mem = 1GB
jobclean_walltime = 100:00:00
jobclean_depend = afterok
#stats (this task is ran per-sample)
stats_nodes =
stats_select = 1
stats_ncpus = 2
stats_threads =
stats_mem = 70GB
stats_walltime = 8:00:00
stats_depend = afterok
#analysis stats (this task is ran per-analysis)
anstats_nodes =
anstats_select = 1
anstats_ncpus = 2
anstats_threads =
anstats_mem = 80GB
anstats_walltime = 5:00:00
anstats_depend = afterok

#Java maximum memory for GATK Programs
javamem_SNCR = Xmx25g
javamem_RTC = Xmx4g
javamem_IR = Xmx4g
javamem_BR = Xmx8g
javamem_PR = Xmx4g
javamem_MD = Xmx4g
javamem_MSF = Xmx4g
javamem_HAPC = Xmx64g
javamem_CV = Xmx100g
javamem_GGVCF = Xmx25g
javamem_VR = Xmx64g
javamem_VF = Xmx64g
javamem_PBT = Xmx8g
javamem_DOC = Xmx64g
javamem_SV = Xmx8g
javamem_CV = Xmx8g
javamem_VA = Xmx8g
javamem_CGP = Xmx8g
javamem_SS = Xmx4g
javamem_BBI = Xmx4g



*************Group 4*******************
###SOFTWARE PARAMETERS
#STAR parameters
STAR_sjdbOverhang = 70

#TrimGalore
trimg_min_qual = 20
clip_R1 = 1
clip_R2 = 1

#Samtools parameters
samsort_threads = 20
samsort_mem = 5G

#SplitNCigarReads parameters
SNCR_read_filter =
SNCR_reassign_mapping_quality_from =
SNCR_reassign_mapping_quality_to =
SNCR_unsafe =

#RealignerTargetCreator
#Known database (referred to known indel and snps in program_config)
#You can separate more with 'word_sep'
known_RTC = known_mills
filter_mismatching_base_and_quals = YES
fix_misencoded_quality_scores = NO
allow_potentially_misencoded_quality_scores = NO
nt_RTC = 10

#IndelRealigner parameters
#Known database (referred to known indel and snps in program_config)
#You can separate more with 'word_sep'
known_IR = known_mills
filter_bases_not_stored = YES

#BaseRecalibrator parameters
#You can separate more with 'word_sep'
known_BR = known_mills,known_db_snp
covariates_BR = ReadGroupCovariate,QualityScoreCovariate,CycleCovariate,ContextCovariate
nct_BR = 10
#Use a single BQSR file
BQSR_uniq = YES

#PrintReads parameters
nct_PR = 8
baq_PR = RECALCULATE

#PICARD TOOLS PARAMETERS
#AddOrReplaceReadGroups parameters
picard_RGID =
picard_RGLB =
picard_RGPL = illumina
picard_RGPU =
picard_RGSM =
picard_RGCN = TIGEM
picard_SORT_ORDER = coordinate
picard_USE_THREADING = true

#MarkDuplicates Parameters
#http://gatkforums.broadinstitute.org/gatk/discussion/2799
#markduplicate is sufficient; HC will automatically apply filters to ignore dupes 
picard_CREATE_INDEX =
picard_VALIDATION_STRINGENCY = LENIENT
picard_REMOVE_DUPLICATES = false
picard_METRICS_FILE = duplicate.metrics
picard_ASSUME_SORTED =
picard_MAX_FILE_HANDLES_FOR_READ_ENDS_MAP =


#HaplotypeCaller parameters (if you use null or none it will not be used )
#GVCF mode is obtained with emitRefConfidence = GVCF
#In GVCF mode the confidence thresholds are set to 0 automatically, so only the GenotypeGVCfs thresholds matter
emitRefConfidence = GVCF
variant_index_type =
variant_index_parameter =
#This parameter is not applied in GVCF mode
HC_stand_call_conf = 50.0
HC_min_base_quality_score = 
HC_dontUseSoftClippedBases =
#Default annotation: BaseQualityRankSumTest,ChromosomeCounts,Coverage,ExcessHet,FisherStrand,HaplotypeScore,InbreedingCoeff,MappingQualityRankSumTest,QualByDepth,RMSMappingQuality,ReadPosRankSumTest,StrandOddsRatio,DepthPerAlleleBySample
hapc_annotation = Coverage,FisherStrand,BaseQualityRankSumTest,HaplotypeScore,InbreedingCoeff,MappingQualityRankSumTest,MappingQualityZero,QualByDepth,RMSMappingQuality,ReadPosRankSumTest,SpanningDeletions
#Old value hapc_dbsnp :known_db_snp
hapc_dbsnp =
nct_HAPC = 8

#GenotypeGVCFs parameters
ggvcf_annotation = Coverage,FisherStrand,BaseQualityRankSumTest,HaplotypeScore,InbreedingCoeff,MappingQualityRankSumTest,MappingQualityZero,QualByDepth,RMSMappingQuality,ReadPosRankSumTest
ggvcf_dbsnp = known_db_snp
#GenotypeGVCF is executed always for multiple samples and for a single sample if the user puts here YES 
do_genotypeGVCF_4_single_sample = YES
#For single sample we reduce the threshold for confidence call
#(https://gatkforums.broadinstitute.org/gatk/discussion/7943/single-sample-vs-multiple-samples-haplotype-caller)
ggvcf_single_sam_stand_call_conf =

#VariantRecalibrator parameters
#Minimum number of exomes to use the VQSR (as given in the GATK Best Practices)
min_samples_4_joint = 30
#Do not use Depth of coverage (DP), HaplotypeScore and InbreedingCoeff for exomes and targeted
#(reason here:https://software.broadinstitute.org/gatk/guide/article?id=1259)
vr_SNP_annotation = QD,MQRankSum,ReadPosRankSum,FS,MQ,SOR
vr_INDEL_annotation = QD,MQRankSum,ReadPosRankSum,FS,SOR
vr_stdThreshold = 10
#Indicate here the number of resources for SNPs and INDELs
vr_numres_SNP = 4
vr_numres_INDEL = 2
vr_resources_SNP1 = hapmap,known=false,training=true,truth=true,prior=15.0
vr_resources_SNP1_file = known_sites_hapmap
vr_resources_SNP2 = omni,known=false,training=true,truth=true,prior=12.0
vr_resources_SNP2_file = known_sites_omni
vr_resources_SNP3 = 1000G,known=false,training=true,truth=false,prior=10.0
vr_resources_SNP3_file = known_sites_1000g
vr_resources_SNP4 = dbsnp,known=true,training=false,truth=false,prior=2.0
vr_resources_SNP4_file = known_sites_db_snp
vr_resources_INDEL1 = mills,known=false,training=true,truth=true,prior=12.0
vr_resources_INDEL1_file = known_sites_mills
vr_resources_INDEL2 = dbsnp,known=true,training=false,truth=false,prior=2.0
vr_resources_INDEL2_file = known_sites_db_snp
#Clusters to generate for different types of variants (default in GATK:2)
vr_max_gaussians_SNP = 2
vr_max_gaussians_INDEL = 2

#ApplyRecalibration parameters
ar_ts_filter_level_SNP =  99.5
ar_ts_filter_level_INDEL =  99.0

#VariantFiltration parameters
#INDEL "QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0"
snp_filters = 1
indel_filters = 4
rna_filters = 5,6
VF_clusterWindowSize = 10
VF_clusterSize =
filterName1 = "HARD_TO_VALIDATE"
filterExpression1 = "QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0"
filterName2 = "VeryLowQual"
filterExpression2 = "QUAL < 25.0"
filterName3 = "LowQual"
filterExpression3 = "QUAL > 25.0 && QUAL < 110.0"
filterName4 = "HARD_TO_VALIDATE"
filterExpression4 = "QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0"
filterName5 = "RNA_FS"
filterExpression5 = "FS > 30.0"
filterName6 = "RNA_QD"
filterExpression6 = "QD < 2.0"


#Genotype Refinement Workflow parameters (GRW)
#VariantFiltration
GRW_genotype_filters = g1
filterName_g1 = "lowGQ"
filterExpression_g1 = "GQ < 20.0"
#VariantAnnotator
GRW_annotation = PossibleDeNovo
GRW_CGP_supporting = known_sites_1000gP3

#Annovar parameters
#ME: If you want to know the distance (in bp) from the exon of those variants annotated as intronics
#KW: use a large -splicing_threshold, such as 50 or 500 or more
annov_splicing_threshold = 50

#Non-covered regions parameters
#Maximum number of reads covering a non-covered regions 
noncov_threshold = 20
#Overlap of non-covered seqs with target seqs during bedtools intersect
noncov_recip_overlap = 0.95

#Plots
#Minimum gene coverage for a gene to be considered "covered"
min_gene_coverage = 10

#Parameters for operations ad-hoc for users
#This parameters are actually activated into the individual user config files
panel_to_tag = 
